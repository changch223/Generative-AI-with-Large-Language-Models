# Generative AI with Large Language Models ‚Äî Learning Notes

This repository contains my personal **learning notes and summaries** from the [Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms) course by DeepLearning.AI and AWS on Coursera. It is intended as a **study companion** and **reference archive** as I explore how Large Language Models (LLMs) power generative AI.

---

## Course Summary

This intermediate-level course consists of three modules:

- **Module 1**: Generative AI foundations, Transformer architecture, project lifecycle
- **Module 2**: Fine-tuning techniques (Instruction tuning, LoRA, Soft Prompts), evaluation metrics
- **Module 3**: Reinforcement Learning with Human Feedback (RLHF), LLM-powered applications, responsible AI

### Instructors:
- Chris Fregly (AWS)
- Antje Barth (AWS)
- Shelbee Eigenbrode (AWS)

---

## Key Learnings

Throughout this course, I learned:

- The typical lifecycle of LLM-powered generative AI projects
- The inner workings of Transformer-based models and how they generate text
- How to engineer prompts for better generation quality
- The differences between full fine-tuning and parameter-efficient fine-tuning (PEFT)
- How RLHF improves model alignment with human preferences
- Various architectural patterns for LLM-based applications like ReAct, PAL, Chain-of-Thought

---

## Labs and Assignments

| Module | Topic | Lab Focus |
|--------|-------|-----------|
| 1 | Generative AI & LLM lifecycle | Text summarization using pre-trained LLM |
| 2 | Fine-tuning & PEFT | Instruction tuning and LoRA |
| 3 | RLHF & LLM apps | Using FLAN-T5 + RLHF for summarization task |

---

## üìÅ Folder Structure

```bash
Generative-AI-with-Large-Language-Models/
‚îú‚îÄ‚îÄ Module1_Foundations/
‚îú‚îÄ‚îÄ Module2_FineTuning/
‚îú‚îÄ‚îÄ Module3_RLHF_Applications/
‚îî‚îÄ‚îÄ README.md
```


Feel free to ‚≠ê star this repository if it helps you in your own AI learning journey!
